{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "load basic packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### First data exploration: structure, data types, missing values \n",
    "\n",
    "(at first only based on one of the files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity = pd.read_csv(\"../data/eccentricity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity['gear_fault_desc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity['load_value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity['speedSet'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity['datetime']= pd.to_datetime(eccentricity['time_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity['time'] = eccentricity['datetime'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity['time_delta'] = eccentricity['datetime'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricity['time_delta'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Load all data, merge all 6 files to one dataframe, add columns with file id and file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(Path(\"../data/\").glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i,f in enumerate(files,start = 1):\n",
    "    df = pd.read_csv(f) \n",
    "    df['file_id'] = i\n",
    "    df['file_name'] = f.name\n",
    "    dfs.append(df)\n",
    "\n",
    "master = pd.concat(dfs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nr = master['file_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Time is of type object. Add a new column `datetime` of type datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "master['datetime'] = pd.to_datetime(master['time_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedSets = master['speedSet'].unique()\n",
    "load_values = master['load_value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_values, speedSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Add a new column trial_id. This is needed because data from multiple trials was saved to one file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Creating the `trial_id` column\n",
    "\n",
    "To split each file into separate trials, following approach was used:\n",
    "\n",
    "1. **Sort the data** by `file_id` and `datetime` so that time differences are computed in the right order.\n",
    "\n",
    "2. **Compute time differences** within each file:\n",
    "   ```python\n",
    "   master[\"time_delta\"] = master.groupby(\"file_id\")[\"datetime\"].diff()\n",
    "\n",
    "3. **Define a sampling rate**, that indicates whenever the time gap is too large or too small\n",
    "\n",
    "4. **Cumulative sum f0r each file_id**\n",
    "    master['trial_id'] = mask.groupby(master['file_id']).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.sort_values(by = ['file_id', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "master['t_delta'] = master.groupby('file_id')['datetime'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = pd.Timedelta(seconds = 0.0002)\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (master['t_delta'].isna()) | (master['t_delta'] != sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "master['trial_id'] = mask.groupby(master['file_id']).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Check if the splitting worked correctly\n",
    "\n",
    "1.**Plotting all trials separately** (`trial_id` and `file_id`)\n",
    "\n",
    "2.**Checking the unique values per file name:** expecting 6 trials in each file (combination of 3 different speed settings and 2 different load values)\n",
    "\n",
    "3.**Using `describe()` per `trial_id` and `file_id`:** Expecting min to be 0.0002.\n",
    "\n",
    "4.**Checking the number of time_delta != sampling_rate per (`trial_id` and `file_id`):** Expecting 1 \n",
    "\n",
    "5.**Checking the number of unique values for `speedSet` and `load_value` per tiral:** Expecting 1 as the conditions should be constant in each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_str = master[\"speedSet\"].map(lambda x: f\"{float(x):.1f}\")\n",
    "\n",
    "master[\"experiment_id\"] = (\n",
    "    master[\"gear_fault_desc\"].str.replace(\" \", \"_\") + \"_\" +\n",
    "    speed_str + \"_\" +\n",
    "    master[\"load_value\"].astype(str))\n",
    "\n",
    "master[\"combo\"] = speed_str + \"/\" + master[\"load_value\"].astype(str)\n",
    "\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "#master[\"experiment_id\"] = master[\"file_id\"].astype(str) + \"_\" + master[\"trial_id\"].astype(str)\n",
    "\n",
    "fig = px.scatter(\n",
    "    master,\n",
    "    x=master.index,\n",
    "    y=\"sensor1\",\n",
    "    color=\"experiment_id\",   # jede (file_id, trial_id)-Kombi eigene Farbe\n",
    "    title=\"Index-Plot farblich nach (file_id, trial_id)\",\n",
    "    labels={\"x\": \"Datenpunkt (Index)\", \"sensor1\": \"sensor1\"},\n",
    "    opacity=0.6,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"experiment_id\",\n",
    "    legend=dict(itemsizing=\"constant\", orientation=\"h\", y=-0.2)  # horizontale Legende unten\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.groupby('file_id')['trial_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.groupby([\"file_id\",\"trial_id\"])[\"t_delta\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_counts = (\n",
    "    master\n",
    "    .groupby([\"file_id\",\"trial_id\"])[\"t_delta\"]\n",
    "    .apply(lambda s: (s != sampling_rate).sum())\n",
    "    \n",
    ")\n",
    "off_counts = off_counts.to_frame(\"off_count\")\n",
    "\n",
    "off_counts['off_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.groupby([\"file_id\",\"trial_id\"])[\"speedSet\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.groupby([\"file_id\",\"trial_id\"])[\"load_value\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Adding two new columns for relative time\n",
    "\n",
    "1.`t_rel`: realtive time per trial (of type timedelta)\n",
    "\n",
    "2.`t_rel_s`: relative time per trial in seconds(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.sort_values(by = ['file_id', 'trial_id'])\n",
    "master['t_rel'] = master.groupby(by=['file_id', 'trial_id']).cumcount() * sampling_rate\n",
    "master.head()\n",
    "master['t_rel'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "master[\"t_rel_s\"] = master[\"t_rel\"].dt.total_seconds()\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Reset index and sort columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.reset_index(drop=True)\n",
    "master.drop('time_x', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['experiment_id', 'combo', 'gear_fault_desc', 'speedSet', 'load_value', 't_rel_s', 'sensor1', 'sensor2']\n",
    "master = master[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### The dataframe master ist now completed and read for. \n",
    "\n",
    "No missing values, correct time columns, corrrectly splitted and labeld trials. \n",
    "\n",
    "Exporting the dataframe as parquet file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_parquet(\"../results/processed/master_clean.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
